{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library) é uma biblioteca de programação de visão computacional e aprendizado de máquina. É uma ferramenta poderosa para processar e analisar imagens e vídeos, amplamente utilizada em diversas áreas como robótica, automação e diagnóstico médico.\n",
    "\n",
    "É uma biblioteca de código aberto voltada para a visão computacional. Com ela, é possível realizar operações complexas em imagens e vídeos, desde a captura e exibição até o processamento avançado como detecção de bordas e transformações geométricas.\n",
    "\n",
    "## Instalação\n",
    "\n",
    "```bash\n",
    "pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Exibição de Imagens\n",
    "\n",
    "Vamos começar com a leitura e exibição de imagens. Primeiro, importe o OpenCV e utilize a função cv2.imread para ler uma imagem e cv2.imshow para exibi-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Ler a imagem\n",
    "imagem = cv2.imread('caminho/para/imagem.jpg')\n",
    "\n",
    "# Exibir a imagem\n",
    "cv2.imshow('Imagem', imagem)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulação de Imagens\n",
    "\n",
    "Convertendo para Escala de Cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Imagem em Cinza', imagem_cinza)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redimensionando imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_redimensionada = cv2.resize(imagem, (largura, altura))\n",
    "cv2.imshow('Imagem Redimensionada', imagem_redimensionada)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recortando imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_recortada = imagem[y_inicial:y_final, x_inicial:x_final]\n",
    "cv2.imshow('Imagem Recortada', imagem_recortada)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações geométricas\n",
    "\n",
    "### Rotacionando imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, w) = imagem.shape[:2]\n",
    "centro = (w // 2, h // 2)\n",
    "\n",
    "matriz_rotacao = cv2.getRotationMatrix2D(centro, angulo, escala)\n",
    "imagem_rotacionada = cv2.warpAffine(imagem, matriz_rotacao, (w, h))\n",
    "\n",
    "cv2.imshow('Imagem Rotacionada', imagem_rotacionada)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translação de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_translacao = np.float32([[1, 0, deslocamento_x], [0, 1, deslocamento_y]])\n",
    "imagem_transladada = cv2.warpAffine(imagem, matriz_translacao, (largura, altura))\n",
    "\n",
    "cv2.imshow('Imagem Transladada', imagem_transladada)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento de vídeo\n",
    "\n",
    "OpenCV também permite a manipulação e o processamento de vídeos. Vamos ler um vídeo e exibir seus frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture('caminho/para/video.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = captura.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplos de código\n",
    "\n",
    "### Exibindo uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "imagem = cv2.imread('caminho/para/imagem.jpg')\n",
    "cv2.imshow('Imagem', imagem)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo para Escala de Cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Imagem em Cinza', imagem_cinza)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de Bordas com Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bordas = cv2.Canny(imagem, 100, 200)\n",
    "cv2.imshow('Bordas', bordas)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento de vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)  # 0 para webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = captura.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção e Reconhecimento de Objetos\n",
    "\n",
    "### Detecção de Objetos com Haar Cascades\n",
    "\n",
    "Haar Cascades são uma forma popular de detectar objetos, especialmente rostos, em uma imagem. Vamos usar um modelo pré-treinado para detecção de rostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Carregar o classificador Haar Cascade para detecção de rostos\n",
    "cascata_rostos = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Ler a imagem e convertê-la para escala de cinza\n",
    "imagem = cv2.imread('caminho/para/imagem.jpg')\n",
    "imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar rostos na imagem\n",
    "rostos = cascata_rostos.detectMultiScale(imagem_cinza, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Desenhar retângulos ao redor dos rostos detectados\n",
    "for (x, y, w, h) in rostos:\n",
    "    cv2.rectangle(imagem, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Exibir a imagem com os rostos detectados\n",
    "cv2.imshow('Rostos Detectados', imagem)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconhecimento de objetos com redes neurais\n",
    "\n",
    "#### Usando um módelo pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o modelo\n",
    "net = cv2.dnn.readNetFromCaffe('caminho/para/deploy.prototxt', 'caminho/para/mobilenet_iter_73000.caffemodel')\n",
    "\n",
    "# Ler a imagem\n",
    "imagem = cv2.imread('caminho/para/imagem.jpg')\n",
    "(h, w) = imagem.shape[:2]\n",
    "\n",
    "# Pré-processar a imagem para o modelo\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(imagem, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# Loop sobre as detecções\n",
    "for i in range(detections.shape[2]):\n",
    "    confiança = detections[0, 0, i, 2]\n",
    "    \n",
    "    # Filtrar detecções fracas\n",
    "    if confiança > 0.2:\n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        caixa = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = caixa.astype(\"int\")\n",
    "        \n",
    "        # Desenhar a caixa ao redor do objeto detectado\n",
    "        label = f\"Objeto: {confiança:.2f}\"\n",
    "        cv2.rectangle(imagem, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        cv2.putText(imagem, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Exibir a imagem com os objetos detectados\n",
    "cv2.imshow('Objetos Detectados', imagem)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
